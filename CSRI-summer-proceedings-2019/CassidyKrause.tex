\documentclass{csri19}

%%% Starting page will be changed when we combine the proceedings
\setcounter{page}{3}

% PACKAGES ---------------------------------------------------------------
\usepackage{amsfonts,amsmath,graphicx,subfigure}
% ADD YOUR OWN PACKAGES HERE ---------------------------------------------
\usepackage{mathtools, amssymb}

% DEFINITIONS ------------------------------------------------------------
% ADD YOUR OWN DEFINITIONS HERE ------------------------------------------
% BE SURE TO PREFACE LABEL WITH YOUR OWN INITIALS (SSS in this example) --
\newcommand{\SSSnorm}[1]{\left\Vert#1\right\Vert}
\newcommand{\SSSabs}[1]{\left\vert#1\right\vert}
\newcommand{\CFKg}{\mathfrak{g}}
\newcommand{\CFKU}{\mathcal{U}}
\newcommand{\CFKV}{\mathcal{V}}

% This controls the table-of-contents entry in the proceedings. Edit it
% to include your article title followed by the authors' names, as shown.
\addcontentsline{toc}{chapter}{Exponential Integrators for the HOMME-NH
Nonhydrostatic Atmosphere Model\\
{\em C.F.\ Krause and A.J.\ Steyer}}

\pagestyle{myheadings}

\thispagestyle{plain}

% This gives the running head. Usually you list a shortened version of
% your article title (unless it's already very short) along with
% the author's names, as shown.
\markboth{Exponential Integrators for HOMME-NH}{C.F.\ Krause and A.J.\ Steyer}

% Put your article title in here
\title{Exponential Integrators for the HOMME-NH Nonhydrostatic Atmosphere
 Model}

% List each author, their affiliation, and their e-mail address, as shown.
\author{Cassidy F.\ Krause\thanks{University of Kansas, ckrause@ku.edu}
\and Andrew J.\ Steyer\thanks{Sandia National Laboratories, asteyer@sandia.gov}}

\begin{document}
\maketitle

% Include your abstract here.
\begin{abstract}
Time-stepping in the HOMME-NH nonhydrostatic atmosphere model requires 
integration of a stiff initial value problem. The current standard is to 
solve these equations using implicit-explicit Runge-Kutta (IMEX RK) 
methods with a horizontally explicit vertically implicit (HEVI) 
partitioning. We introduce a horizontally explicit vertically integrating 
factor exponential (HEVIE) method as an alternative to solving 
these stiff equations. The benefit of exponential methods is that they 
allow a larger step-size than explicit methods; however, their main 
drawback is the cost of forming the matrix exponential. Here, we show that 
we can mitigate this cost by taking advantage of the tridiagonal-like form 
of our Jacobian and parallelizing our computations, making this solver an 
attractive option for HOMME-NH.
\end{abstract}

\section{Introduction} \label{CFK:sec:intro}
Stiff initial value problems, like those found in the HOMME-NH 
nonhydrostatic atmosphere model, require a small step-size when integrated 
with an explicit method. (For a thorough description of HOMME-NH, see 
\cite{CFK:preprint}.) On the other hand, using a fully implicit method 
requires nonlinear solves, which are computationally expensive. To deal 
with these restrictions, many approaches have been developed for solving 
stiff equations. One of these approaches is implicit-explicit Runge-Kutta 
(IMEX RK) methods, which are currently implemented in HOMME-NH. A second 
approach to solving stiff initial value problems is exponential-type 
integrators, which we consider in this paper as an alternative to IMEX RK 
methods for HOMME-NH. We briefly introduce these two types of methods 
below.

Consider an equation of the form \[ \CFKU_t = f(\CFKU) = s(\CFKU) + 
n(\CFKU),\] where $s(\CFKU)$ contains the stiff part of the equation, and 
$n(\CFKU)$ contains the nonstiff part. IMEX RK methods use an implicit RK 
method on $s(\CFKU)$, and an explicit RK method to integrate $n(\CFKU)$. 
These IMEX RK methods are implemented in HOMME-NH with a horizontally 
explicit vertically implicit (HEVI) partitioning (\cite{CFK:Steyer2019}, 
\cite{CFK:Vogl2019}).

In this paper, we consider a class of exponential integrators, namely 
integrating factor Runge-Kutta (IFRK) methods, as an alternative integrator 
for HOMME-NH with a horizontally explicit vertically integrating factor 
exponential (HEVIE) partitioning. With IFRK methods, we split our equation 
as \[ \CFKU_t = f(\CFKU) = L_m\CFKU +  N_m(\CFKU),\] where $L_m$ is a 
linear operator containing the stiff part of the equation, and $N_m(\CFKU) 
= f(\CFKU)-L_m\CFKU$ contains the nonstiff terms. Often, $L_m = f'(\CFKU)$, 
but we do not assume this is the case. Using the change of variables 
$\CFKV(t) = e^{-L_m(t-t_m)}\CFKU(t)$, we have \begin{equation}
\label{CFK:eqn:vode}
\CFKV_t = e^{-L_m(t-t_m)}N_m(e^{L_m(t-t_m)}\CFKV). \end{equation} 
We then use a fully explicit $r-$stage RK method to solve equation 
\ref{CFK:eqn:vode}, as explained in Section \ref{CFK:sec:ifrk}.

The most expensive part of any exponential-type integrator, including IFRK 
methods, is the formation of the matrix exponential. However, the structure 
of the Jacobian in HOMME-NH allows us to form these matrix exponentials 
quickly and in parallel, making this a viable alternative to the IMEX 
RK methods.

The rest of the paper is structured as follows: In Section 
\ref{CFK:sec:matexp} we give a brief background of numerical approximations 
of the matrix exponential; Section \ref{CFK:sec:homme} discusses the 
implementation of IFRK methods with HOMME-NH; Section \ref{CFK:sec:ifrk} 
details the specific IFRK methods we use in this paper; and numerical 
results are given in Section \ref{CFK:sec:results}.

\section{Numerical Approximation of the Matrix Exponential}
\label{CFK:sec:matexp} 
While exponential integrators allow for a larger time step than explicit 
methods, a major drawback is the computational cost of forming the matrix 
exponential. For this reason, matrix exponential methods were seldom used 
in practice, but advances in efficiently forming $e^A$ have recently made 
exponential-type methods a competetive choice for integrating stiff initial 
value problems (e.g., \cite{CFK:Clancy2013}, \cite{CFK:Garcia2014}).

The matrix exponential $e^A$ can be analytically computed if the matrix $A$ 
is diagonalizable, but finding the eigenvalues of $A$ is expensive, and it 
is not generally guaranteed that $A$ is diagonalizable. A more efficient 
approach is to approximate $e^{A}$ using a Pad\'e or Taylor series 
approximation. Other methods of approximating the matrix exponential are 
discussed in \cite{CFK:Moler2003}.

We choose to implement a $(p,q)$-Pad\'e approximation 
$e^{A}\approx \left[Q_{pq}(A)\right]^{-1}P_{pq}(A)$, where $P_{pq}(A)$ and 
$Q_{pq}(A)$ are defined as follows:

\begin{align}
\label{CFK:eqn:PadeP}
P_{pq}(A) &= \sum_{j=0}^p\frac{(p+q-j)!p!}{(p+q)!j!(p-j)!}A^j\\
\label{CFK:eqn:PadeQ}
Q_{pq}(A) &= \sum_{j=0}^q\frac{(p+q-j)!q!}{(p+q)!j!(q-j)!}(-A)^j
\end{align}

After we calculate the terms $P_{pq}$ and $Q_{pq}$, the product 
$e^A\approx\left[Q_{pq}(A)\right]^{-1}P_{pq}(A)$ is a potentially expensive 
computation because of the matrix inversion. Fortunately, for our 
application, the matrix $A$ we consider has a special structure that allows 
us to approximate $e^A$ efficiently and accurately. This implementation is 
further discussed in Section \ref{CFK:sec:homme}.

The error for the $(p,q)$-Pad\'e approximation is given by
\[e^A-\left[Q_{pq}(A)\right]^{-1}P_{pq}(A) = \mathcal{O}(\|A\|^{p+q+1}),\] 
though in practice, this may be a particularly pessimistic estimation of 
the error, as shown in Table \ref{CFK:tab:PadeError}. If the matrix $A$ is 
ill-conditioned, the Pad\'e  approximation can be especially inaccuarate. 
To mitigate this problem, we implement a scaling and squaring approach. We 
briefly outline this procedure here; for further detail and error analysis 
of the scaling and squaring method, see \cite{CFK:Al-Mohy2009} and 
\cite{CFK:higham2005}.


To scale $e^A$, we take advantage of the properties of matrix exponentials 
and write it as
\[e^{A} = \left(e^{A/k}\right)^k,\]
where we choose $k$ to be the smallest power of $2$ so that $\|A/k\|_2
\leq 0.5$. With this factorization, the matrix $A$ is scaled down to $A/k$, 
and the matrix exponential $e^{A/k}$ is calculated using the Pad\'e 
formulas given in equations \ref{CFK:eqn:PadeP} and \ref{CFK:eqn:PadeQ}. 
The resulting matrix exponential is then squared repeatedly to recover the 
desired matrix exponential $e^{A}$. This numerical approximation to the 
matrix exponential $e^A$ is then used with an explicit $r$-stage RK method, 
as described in Section \ref{CFK:sec:ifrk}, to solve equation 
\ref{CFK:eqn:vode}.

\section{Implementation with HOMME-NH}\label{CFK:sec:homme}
As mentioned in Section \ref{CFK:sec:matexp}, the specific structure of 
the Jacobian in HOMME-NH allows us to form the matrix exponential $e^A 
\approx \left[Q_{pq}(A)\right]^{-1}P_{pq}(A)$ efficiently. HOMME-NH is a 
nonhydrostatic atmosphere model whose state variables are listed in Table 
\ref{CFK:tab:variables}. 
\begin{table}[ht]
  \caption{Variables in HOMME-NH}
  \label{CFK:tab:variables}
  \begin{center}
    \begin{tabular}{|c|l|}
      \hline
      \textbf{Variable Name} & \textbf{Description} \\
      \hline
      $\CFKg$                       & Gravitational constant                                  \\
      $\vec{u}=\left(u,v\right)^T$  & Horizontal velocity                                     \\
      $w$                           & Vertical velocity                                       \\
      $\phi$                        & Geopotential                                            \\
      $\theta$                      & Potential temperature                                   \\
      $\pi$                         & Hydrostatic pressure                                    \\
      $\eta$                        & Mass-based hybrid terrain-following vertical coordinate \\
      $p_{nh}$                      & Nonhydrostatic pressure                                 \\
      $\mu$                         & $\frac{\partial p_{nh}}{\partial\eta}/\frac{\partial\pi}{\partial\eta}$  \\
      \hline
    \end{tabular}
  \end{center}
\end{table}
The stiff terms in this model are 
$w$ and $\phi$, so we can write the governing equations as
\[ \CFKU_t \coloneqq \begin{bmatrix} \vec{u_t} \\
w_t\\
\phi_t\\
\theta_t\\
\frac{\partial \pi}{\partial \eta}
\end{bmatrix} = n(\CFKU) + s(\CFKU),\text{ with }
 s(\CFKU) = \begin{bmatrix}
0\\
-\CFKg (1-\mu)\\
\CFKg w\\
0\\
0\end{bmatrix}.\]

Linearizing $s(\CFKU)$ gives the following Jacobian:
\[ J = \begin{bmatrix}
0&                  &                                                   &  & \\
 & 0                & \CFKg \Delta t \frac{\partial \mu}{\partial \phi} &  & \\
 & \CFKg \Delta t I & 0                                                 &  & \\
 &                  &                                                   &0 & \\
 &                  &                                                   &  &0\end{bmatrix},\]

where $\dfrac{\partial \mu}{\partial \phi}$ is tridiagonal. Then
\[ e^J = \begin{bmatrix}
I&                                                                     &  & \\
 & \exp\left(\begin{bmatrix}0 & \CFKg \Delta t \frac{\partial \mu}{\partial \phi} \\ 
  \CFKg \Delta t I & 0     \end{bmatrix}\right)     &  & \\                                      
 &                                                                     &I & \\
 &                                                                     &  &I\end{bmatrix}.\]

So, forming $e^{\alpha J}$ reduces to forming an exponential of the 
tridiagonal-like matrix $A \coloneqq 
\begin{bmatrix}
   0              & \CFKg \Delta t \frac{\partial \mu}{\partial \phi} \\
 \CFKg \Delta t I & 0  \end{bmatrix}$, and the matrix exponential will 
only act on variables $w$ and $\phi$. 

The structure of $A$ allows us to solve 
$e^A \approx \left[Q_{pq}(A)\right]^{-1}P_{pq}(A)$ using tridiagonal solves 
and back substitution. To do so, we first factor $Q_{pq}(A)$ as
\begin{align*}
Q_{pq}(A) &= \sum_{j=0}^q\frac{(p+q-j)!q!}{(p+q)!j!(q-j)!}(-A)^j\\
          &= \kappa\prod_{j=1}^q\left[\sigma_jI-A\right],
\end{align*}
where $\sigma_j\in \mathbb{C}$ for $j=1,\dots,q$.

Then, since we want to solve for 
$R \coloneqq \left[Q_{pq}(A)\right]^{-1}P_{pq}(A)$, we have
\begin{align*}
Q_{pq}(A) R &= P_{pq}(A)\\
\prod_{j=1}^q\left[\sigma_jI-A\right]R &= \frac{1}{\kappa}P_{pq}(A).
\end{align*}

Define $R_1 \coloneqq \left[\sigma_2I-A\right]\left[\sigma_3I-A\right]
\cdots\left[\sigma_qI-A\right]R$. Then our equation becomes
\begin{equation}\label{CFK:eqn:PadeApprox} \left[\sigma_1I-A\right]R_1 
= \frac{1}{\kappa}P_{pq}(A).\end{equation} Note that
$\left[\sigma_1I-A\right] =
 \begin{bmatrix} \sigma_1 I  & -\CFKg\Delta t \frac{\partial\mu}{\partial\phi} \\
 -\CFKg\Delta t I            & \sigma_1 I \end{bmatrix}.$ This form allows 
us to solve for $R_1$ using far fewer operations than if 
$\left[\sigma_1I-A\right]$ were a full matrix. To do this, we similarly 
partition $R_1$ and $\frac{1}{\kappa}P_{pq}(A)$ into block matrices:
\[ R_1 = \begin{bmatrix} \hat{R_1} \\ \hat{R_2}\end{bmatrix} \qquad P_{pq}(A) = \begin{bmatrix} \hat{P_1} \\ \hat{P_2}\end{bmatrix}.\]
Then equation \ref{CFK:eqn:PadeApprox} becomes
\[\begin{bmatrix} \sigma_1 I  & -\CFKg\Delta t \frac{\partial\mu}{\partial\phi} \\
           -\CFKg\Delta t I & \sigma_1 I \end{bmatrix}
\begin{bmatrix} \hat{R_1} \\
 \hat{R_2} \end{bmatrix} = 
\begin{bmatrix} \hat{P_1} \\
 \hat{P_2} \end{bmatrix}.\]

If $\sigma_1 = 0$ this decomposes to a tridiagonal linear solve and a trivial solve. 
If $\sigma_1 \neq 0$, then we left multiply by $\begin{bmatrix} I & 0 \\
                                     \CFKg\Delta t \sigma_1^{-1}I & I \end{bmatrix}$ to obtain:
\[\begin{bmatrix} 
 \sigma_1 I  & -\CFKg\Delta t \frac{\partial\mu}{\partial\phi} \\
         0 & \sigma_1 I -\left(\CFKg\Delta t\right)^2  \sigma_1^{-1}\frac{\partial\mu}{\partial\phi}
 \end{bmatrix}
 \begin{bmatrix} \hat{R_1} \\
 \hat{R_2} \end{bmatrix} = 
\begin{bmatrix} \hat{P_1} \\
 \CFKg\Delta t \sigma_1^{-1} \hat{P_1} +  \hat{P_2} \end{bmatrix}.\]
The matrix block $\left[\sigma_1 I -\left(\CFKg\Delta t\right)^2\sigma_1^{-1}\frac{\partial\mu}{\partial\phi}\right]$ 
is tridiagonal since $\frac{\partial\mu}{\partial\phi}$ is tridiagonal. 
Therefore we can solve for $\hat{R_2}$ with a tridiagonal 
solve:
\[\left[\sigma_1 I -\left(\CFKg\Delta t \right)^2  \sigma_1^{-1}\frac{\partial\mu}{\partial\phi}\right]\hat{R_2}
 = \left[\CFKg\Delta t\sigma_1^{-1} \hat{P_1} +  \hat{P_2}\right],\]
and then form $\hat{R_1}$ as 
\[\hat{R_1} = \sigma_1^{-1}\left[P_1 + \CFKg\Delta t\frac{\partial \mu}{\partial \phi}\right] \hat{R_2}.\]

In this way, we have just solved equation \ref{CFK:eqn:PadeApprox} for $R_1 = \begin{bmatrix} \hat{R_1}\\ \hat{R_2}\end{bmatrix}$. 
On the other hand, we also have
\[\left[\sigma_2I-A\right]\left[\sigma_3I-A\right]\cdots\left[\sigma_qI-A\right]R = R_1.\] 
We can iteratively repeat the same procedure, defining 
\[R_j \coloneqq \left[\sigma_{j+1}I-A\right]\left[\sigma_{j+2}I-A\right]\cdots\left[\sigma_qI-A\right]R\]
 and solving 
\[\left[\sigma_jI-A\right]R_j = R_{j-1}\] for $R_j$, continuing 
in this way until we arrive at \[\left[\sigma_qI-A\right]R = R_{q-1}.\] 
Solving this last tridiagonal system gives us the $R = \left[Q_{pq}(A)\right]^{-1}P_{pq}(A)\approx e^A$
 that we are looking for.

This algorithm for computing $R \approx e^A$ is particularly efficient if 
the values of $p$ and $q$ are small, so that we can compute $\{\sigma_j\}_
{j=1}^q$ by hand ahead of time. To validate the use of a $(p,q)$-Pad\'e 
approximation, and to determine how large $p$ and $q$ must be, we let the 
model spin up to 15 days and consider the Jacobian at that timestep. In 
HOMME-NH, the Jacobian will always have unique, purely imaginary 
eigenvalues. This allows us to calculate the matrix exponential 
analytically and compare it to the $(p,q)$-Pad\'e approximation.

To calculate $e^A$ analytically, suppose $\lambda_1, \lambda_2, \dots, 
\lambda_k$ are the unique eigenvalues of $A$, and $V$ is the matrix of 
corresponding eigenvectors. Then the Schur decomposition of $A$ is 
\[A = V \begin{bmatrix} \lambda_1 &           &        &           \\
                                  & \lambda_2 &        &           \\
                                  &           & \ddots &           \\
                                  &           &        & \lambda_k \end{bmatrix}
 V^{-1},\] and the matrix exponential can be analytically computed to 
machine precision as
\begin{align*}
e^A &= V \exp\left(\begin{bmatrix} \lambda_1 &           &        &           \\
                                             & \lambda_2 &        &           \\
                                             &           & \ddots &           \\
                                             &           &        & \lambda_k \end{bmatrix}\right) V^{-1} \\
  &= V \begin{bmatrix} e^\lambda_1 &             &        &             \\
                                   & e^\lambda_2 &        &             \\
                                   &             & \ddots &             \\
                                   &             &        & e^\lambda_k \end{bmatrix} V^{-1}.
\end{align*}
Table \ref{CFK:tab:PadeError} gives the error of several diagonal $(p,q)$-
Pad\'e approximations, for different values of $p=q$.
\begin{table}[ht]
  \begin{center}
    \caption{Error of Pad\'e approximation as compared to analytic 
               computation of $e^A$.}
    \label{CFK:tab:PadeError}
    \begin{tabular}{|c|c|}
      \hline
      \textbf{Value of $p=q$} & \textbf{Error}\\
      \hline
      2 & 1.30e-10 \\
      3 & 5.25e-13 \\
      4 & 4.92e-13 \\
      5 & 5.42e-13 \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

Since a $(2,2)$-Pad\'e approximation yields a considerably accurate matrix 
exponential and also gives the benefit of easily solving for the 
coefficients $\{\sigma_1, \sigma_2\}$ ahead of time, this is the 
approximation we choose to implement in our IFRK methods.

\section{Integrating Factor Runge-Kutta Methods}\label{CFK:sec:ifrk}
The focus of this paper is to implement IFRK methods in the HOMME-NH 
nonhydrostatic atmosphere model. IFRK methods were introduced in 
\cite{CFK:Lawson1969}, shown to be a type of exponential RK method by
\cite{CFK:Minchev2006}, and proven to be strong stability preserving (SSP) 
by \cite{CFK:Isherwood2018}.

For IFRK methods, we use an explicit $r$-stage RK method to solve 
equation \ref{CFK:eqn:vode}. If the Butcher tableau is given by 
$\begin{array}{c|c}
c & A \\ \hline & b^T \end{array}$, then the solution to equation \ref{CFK:eqn:vode} 
with initial condition $v(t_0) = v_0$ and step-size $\Delta t$ is given by
\[ \left\{\begin{array}{l} v_{m+1} = v_m + \Delta t\sum_{k=1}^r b_k 
                         e^{-L_m(t_{m,k}-t_m)}N(e^{L_m(t_{m,k}-t_m)}g_k) \\
          g_j = v_m + \Delta t \sum_{k=1}^r A_{j,k} e^{-L_m(t_{m,k} - t_m)} 
                      N(e^{L_m(t_{m,k}-t_m)}g_k), \end{array} \right. \]
for $j = 1,\dots,r$, where $t_{m,k} = t_m + c_k \Delta t$.
The naming convention we use for the explicit $r$-stage RK methods is ``$ERK
-nm$,'' where $n$ is the order of the method, and $m$ is the number of
stages. Here, we consider four explicit RK methods, given by the Butcher 
tableaux below.
\begin{align*}&\text{ERK-}13:
 \begin{array}{c|ccc}
0   & 0   & 0 & 0\\
1/2 & 1/2 & 0 & 0\\
1   & 0   & 1 & 0\\
\hline
    & 0   & 1 & 0
\end{array}
& \text{ERK-}36: 
\begin{array}{c|cccccc}
0   & 0   & 0   & 0   & 0   & 0   & 0\\
1/5 & 1/5 & 0   & 0   & 0   & 0   & 0\\
1/5 & 0   & 1/5 & 0   & 0   & 0   & 0\\
1/3 & 0   & 0   & 1/3 & 0   & 0   & 0\\
2/3 & 0   & 0   & 0   & 2/3 & 0   & 0\\
1   & 1/4 & 0   & 0   & 0   & 3/4 & 0\\
\hline
    & 1/4 & 0   & 0   & 0   & 3/4 & 0
\end{array}\\
\\
&\text{ERK-}24: 
\begin{array}{c|cccc}
0   & 0   & 0   & 0 & 0\\
1/2 & 1/2 & 0   & 0 & 0\\
1/2 & 0   & 1/2 & 0 & 0\\
1   & 0   & 0   & 1 & 0\\
\hline
    & 0   & 0   & 1 & 0
\end{array}
& \text{ERK-}44: 
\begin{array}{c|cccc}
0   & 0   & 0   & 0   & 0 \\
1/2 & 1/2 & 0   & 0   & 0 \\
1/2 & 0   & 1/2 & 0   & 0 \\
1   & 0   & 0   & 1   & 0 \\
\hline
    & 1/6 & 1/3 & 1/3 & 1/6
\end{array} 
\end{align*}

\section{Results}\label{CFK:sec:results}
After implementing each of the methods described in Section 
\ref{CFK:sec:ifrk} into HOMME-NH, we tested their convergence. For the 
``truth'', we compared our exponential integrating factor methods to a 
third order, five stage Ullrich method (described in \cite{CFK:Guerra2016}) 
with a timestep of $10^{-5}$, calculating the maximum $2$-norm error over 
all latitudes and longitudes. To verify our methods, we calculate the error 
of the stiff variables, $w$ and $\phi$, which the matrix exponential acts 
upon. We also calculate the error of $u$ and $v$, which the matrix 
exponential does not affect, as reference variables. The absolute errors 
are listed in Table \ref{CFK:tab:abs_err}, and the relative errors are 
listed in Table \ref{CFK:tab:rel_err}.

\begin{table}[ht]
  \centering
  \caption{Absolute error of state variables}
  \label{CFK:tab:abs_err}
  \scalebox{0.6}{\subtable[Absolute error of $u$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $3.11$e-$4$ \\
      ERK-13          & $0.01$            & $3.12$e-$6$ \\
      ERK-13          & $0.001$           & $1.07$e-$6$ \\
      \hline
      ERK-24          & $0.1$             & $2.84$e-$4$ \\
      ERK-24          & $0.01$            & $2.83$e-$6$ \\
      ERK-24          & $0.001$           & $1.07$e-$6$ \\
      \hline
      ERK-36          & $0.1$             & $1.07$e-$6$ \\
      ERK-36          & $0.01$            & $1.07$e-$6$ \\
      ERK-36          & $0.001$           & $1.07$e-$6$ \\
      \hline
      ERK-44          & $0.1$             & $1.07$e-$6$ \\
      ERK-44          & $0.01$            & $1.07$e-$6$ \\
      ERK-44          & $0.001$           & $1.07$e-$6$
    \end{tabular}}}
  \quad
  \scalebox{0.6}{\subtable[Absolute error of $v$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $3.22$e-$4$ \\
      ERK-13          & $0.01$            & $3.22$e-$6$ \\
      ERK-13          & $0.001$           & $6.52$e-$7$ \\
      \hline
      ERK-24          & $0.1$             & $2.93$e-$4$ \\
      ERK-24          & $0.01$            & $2.93$e-$6$ \\
      ERK-24          & $0.001$           & $6.52$e-$7$ \\
      \hline
      ERK-36          & $0.1$             & $6.55$e-$7$ \\
      ERK-36          & $0.01$            & $6.52$e-$7$ \\
      ERK-36          & $0.001$           & $6.52$e-$7$ \\
      \hline
      ERK-44          & $0.1$             & $6.53$e-$7$ \\
      ERK-44          & $0.01$            & $6.52$e-$7$ \\
      ERK-44          & $0.001$           & $6.52$e-$7$
    \end{tabular}}}\quad
  \scalebox{0.6}{\subtable[Absolute error of $w$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $1.02$e-$1$ \\
      ERK-13          & $0.01$            & $1.02$e-$3$ \\
      ERK-13          & $0.001$           & $1.11$e-$5$ \\
      \hline
      ERK-24          & $0.1$             & $1.02$e-$1$ \\
      ERK-24          & $0.01$            & $1.02$e-$3$ \\
      ERK-24          & $0.001$           & $1.11$e-$5$ \\
      \hline
      ERK-36          & $0.1$             & $7.54$e-$4$ \\
      ERK-36          & $0.01$            & $2.00$e-$6$ \\
      ERK-36          & $0.001$           & $1.49$e-$6$ \\
      \hline
      ERK-44          & $0.1$             & $2.30$e-$4$ \\
      ERK-44          & $0.01$            & $1.49$e-$6$ \\
      ERK-44          & $0.001$           & $1.49$e-$6$
    \end{tabular}}}\quad
   \scalebox{0.6}{\subtable[Absolute error of $\phi$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $1.81$e-$1$ \\
      ERK-13          & $0.01$            & $1.81$e-$3$ \\
      ERK-13          & $0.001$           & $1.16$e-$4$ \\
      \hline
      ERK-24          & $0.1$             & $1.81$e-$1$ \\
      ERK-24          & $0.01$            & $1.81$e-$3$ \\
      ERK-24          & $0.001$           & $1.16$e-$4$ \\
      \hline
      ERK-36          & $0.1$             & $3.70$e-$3$ \\
      ERK-36          & $0.01$            & $1.15$e-$4$ \\
      ERK-36          & $0.001$           & $1.15$e-$4$ \\
      \hline
      ERK-44          & $0.1$             & $4.19$e-$4$ \\
      ERK-44          & $0.01$            & $1.15$e-$4$ \\
      ERK-44          & $0.001$           & $1.15$e-$4$
    \end{tabular}}}
\end{table}

\begin{table}[ht]
  \centering
  \caption{Relative error of state variables}
  \label{CFK:tab:rel_err}
  \scalebox{0.6}{\subtable[Relative error of $u$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $3.48$e-$6$ \\
      ERK-13          & $0.01$            & $6.31$e-$8$ \\
      ERK-13          & $0.001$           & $6.31$e-$8$ \\
      \hline
      ERK-24          & $0.1$             & $3.17$e-$6$ \\
      ERK-24          & $0.01$            & $6.31$e-$8$ \\
      ERK-24          & $0.001$           & $6.31$e-$8$ \\
      \hline
      ERK-36          & $0.1$             & $6.31$e-$8$ \\
      ERK-36          & $0.01$            & $6.31$e-$8$ \\
      ERK-36          & $0.001$           & $6.31$e-$8$ \\
      \hline
      ERK-44          & $0.1$             & $6.31$e-$8$ \\
      ERK-44          & $0.01$            & $6.31$e-$8$ \\
      ERK-44          & $0.001$           & $6.31$e-$8$
    \end{tabular}}}
  \quad
  \scalebox{0.6}{\subtable[Relative error of $v$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $1.79$e+$1$ \\
      ERK-13          & $0.01$            & $8.88$e-$1$ \\
      ERK-13          & $0.001$           & $8.88$e-$1$ \\
      \hline
      ERK-24          & $0.1$             & $1.68$e+$1$ \\
      ERK-24          & $0.01$            & $8.95$e-$1$ \\
      ERK-24          & $0.001$           & $8.88$e-$1$ \\
      \hline
      ERK-36          & $0.1$             & $8.88$e-$1$ \\
      ERK-36          & $0.01$            & $8.88$e-$1$ \\
      ERK-36          & $0.001$           & $8.88$e-$1$ \\
      \hline
      ERK-44          & $0.1$             & $8.88$e-$1$ \\
      ERK-44          & $0.01$            & $8.88$e-$1$ \\
      ERK-44          & $0.001$           & $8.88$e-$1$
    \end{tabular}}}\quad
  \scalebox{0.6}{\subtable[Relative error of $w$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $1.41$e+$8$ \\
      ERK-13          & $0.01$            & $1.41$e+$6$ \\
      ERK-13          & $0.001$           & $1.41$e+$4$ \\
      \hline
      ERK-24          & $0.1$             & $1.41$e+$8$ \\
      ERK-24          & $0.01$            & $1.41$e+$6$ \\
      ERK-24          & $0.001$           & $1.41$e+$4$ \\
      \hline
      ERK-36          & $0.1$             & $1.04$e+$6$ \\
      ERK-36          & $0.01$            & $1.09$e+$3$ \\
      ERK-36          & $0.001$           & $5.27$e+$1$ \\
      \hline
      ERK-44          & $0.1$             & $3.18$e+$5$ \\
      ERK-44          & $0.01$            & $8.82$e+$1$ \\
      ERK-44          & $0.001$           & $5.18$e+$1$
    \end{tabular}}}\quad
  \scalebox{0.6}{\subtable[Relative error of $\phi$]{\begin{tabular}{c|c|c}
      \textbf{Method} & \textbf{$\Delta t$} & \textbf{Error}\\
      \hline
      ERK-13          & $0.1$             & $7.15$e-$7$ \\
      ERK-13          & $0.01$            & $7.17$e-$9$ \\
      ERK-13          & $0.001$           & $4.60$e-$10$ \\
      \hline
      ERK-24          & $0.1$             & $7.15$e-$7$ \\
      ERK-24          & $0.01$            & $7.17$e-$9$ \\
      ERK-24          & $0.001$           & $4.60$e-$10$ \\
      \hline
      ERK-36          & $0.1$             & $1.47$e-$8$ \\
      ERK-36          & $0.01$            & $4.53$e-$10$ \\
      ERK-36          & $0.001$           & $4.53$e-$10$ \\
      \hline
      ERK-44          & $0.1$             & $1.66$e-$9$ \\
      ERK-44          & $0.01$            & $4.53$e-$10$ \\
      ERK-44          & $0.001$           & $4.53$e-$10$
    \end{tabular}}}
\end{table}

Note that the value of $w$ is small, so even though the absolute error 
of the IFRK methods is satisfactory, the relative error is rather
 large. Recall from Table \ref{CFK:tab:PadeError} that the error of the 
$(2,2)$-Pad\`e approximation that we are implementing is $\mathcal{O}(10^{-10})$.
This doesn't take into account the error from the IFRK method itself, 
and combining this error with the loss of digits that may happen because of 
the small values of $w$, it is not surprising that the relative error of 
$w$ is larger than that of the other variables.

We graph these errors in Figure \ref{CFK:fig:convtest}. The slope of these 
methods flattens out as the timestep goes to zero. One possible 
explanation for this is that the accuracy may be limited by the accuracy of 
the matrix exponential.

\begin{figure}[ht]
\label{CFK:fig:convtest}
\begin{center}
\begin{tabular}{cc}
\scalebox{0.15}{\includegraphics{plots/CFKu_err.png}} 
&
\scalebox{0.15}{\includegraphics{plots/CFKu_err_rel.png}}
\\
\scalebox{0.15}{\includegraphics{plots/CFKv_err.png}} 
&
\scalebox{0.15}{\includegraphics{plots/CFKv_err_rel.png}}
\end{tabular}
\end{center}
\caption{Log-log plot of errors of IFRK methods.}
\end{figure}
\newpage
\begin{figure}[ht]
\label{CFK:fig:convtest1}
\begin{center}
\begin{tabular}{cc}
\scalebox{0.15}{\includegraphics{plots/CFKw_err.png}} 
&
\scalebox{0.15}{\includegraphics{plots/CFKw_err_rel.png}}
\\
\scalebox{0.15}{\includegraphics{plots/CFKphi_err.png}} 
&
\scalebox{0.15}{\includegraphics{plots/CFKphi_err_rel.png}}
\end{tabular}
\end{center}
\caption{Log-log plot of errors of IFRK methods, continued.}
\end{figure}

\section{Conclusions}
Another important matter to take into consideration is that the Jacobian 
at each point of our discretization scheme can be computed at the 
beginning of each time step, and we can do this computation in parallel. 
Furthermore, the IFRK methods rely only on the local-in-time Jacobian, so 
we can do the IFRK computation in parallel as well.

The IFRK methods allow us to deal with stiff initial value problems with a 
larger step-size than a fully explicit method, and the opportunity for 
parallelization with HOMME-NH boosts efficiency. Though the formation of 
the matrix exponential can be a costly computation, we are able to take 
advantage of the tridiagonal-like form of the Jacobian in HOMME-NH, to 
implement the IFRK methods in a way that mitigates the cost of forming the 
matrix exponential.

We have shown that IFRK methods are accurate and can be implemented in 
parallel. However, more work is needed to compare the efficiency of these 
methods, which will determine if IFRK methods can be competitive with 
the IMEX RK methods that are currently implemented in HOMME-NH. In 
particular, the efficiency of the IFRK methods will depend on how large of 
a step-size they can take, and this remains to be done.

\newpage
\bibliographystyle{siam}
% Edit the line below to be your first and last names.
\bibliography{CassidyKrause}

% Edit FirstnameLastname below to be your first and last names, but leave the line commented out.
% This line will help me merge bibliographies for the proceedings.
%\input{CassidyKrause.bbl}

\end{document}
